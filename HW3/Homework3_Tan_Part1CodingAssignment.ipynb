{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3 - Improving the Pipeline \n",
    "# Part 1: Coding Assignment\n",
    "\n",
    "CAPP 30235 Machine Learning for Public Policy\n",
    "\n",
    "Jonathan Tan\n",
    "\n",
    "May 2, 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import pipeline library, hardcoded config file values\n",
    "import pipeline_library as library\n",
    "import pipeline_config as config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Fix and improve the pipeline code you submitted for the last assignment based on the feedback from the TA. if something critical was pointed out in the feedback, you need to fix it. You'll get the last homework back by ends of thursday so you'll still have time before this one is due to address those comments.\n",
    "\n",
    "I received no feedback from my last assignment, so I have skipped this step.\n",
    "\n",
    "### 2. Add more classifiers to the pipeline. It should at least have Logistic Regression, KÂ­Nearest Neighbor, Decision Trees, SVM, Random Forests, Boosting, and Bagging. The code should have a parameter for running one or more of these classifiers and your analysis should run all of them.\n",
    "\n",
    "#### 2.1 `train_classifier()`\n",
    "\n",
    "`train_classifier()` takes 2 pandas DataFrames (features and labels of training data) and the name of a classifier to fit. It optionally takes a nested dictionary of hyperparameters to use for each. (For this notebook, these parameters can be changed in the `pipeline_config.py` file.) It returns a trained classifier object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate train_classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Experiment with different parameters for these classifiers (different values of k for example, as well as parameters that other classifiers have). You should look at the sklearn documentation to see what parameter each classifier can take and what the default values sklearn selects. The labs should be helpful here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Add additional evaluation metrics that we've covered in class to the pipeline (accuracy, precision at different levels, recall at different levels, F1, area under curve, and precision-recall curves).\n",
    "\n",
    "#### 4.1 `validate_classifier()`\n",
    "\n",
    "`validate_classifier()` takes 2 dataframes (features and labels for test data) and a pre-trained classifier object as inputs, calculates several evaluation metrics (accuracy, precision, recall, F1, etc.) and returns a dictionary of those metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate validate_classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Create temporal validation function in your pipeline that can create training and test sets over time. You can choose the length of these splits based on analyzing the data. For example, the test sets could be six months long and the training sets could be all the data before each test set.\n",
    "\n",
    "#### 5.1 `split_data_temporal()`\n",
    "\n",
    "`split_data_temporal()` takes a pandas DataFrame and specified label/date column names as inputs, then splits the dataframe on the specified timeframe. The default test set duration is the most recent 1 year of data. It returns two dataframes and two series in order:\n",
    " 1. training features\n",
    " 2. test features\n",
    " 3. training labels\n",
    " 4. test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate split_data_temporal()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
